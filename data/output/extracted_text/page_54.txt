SEC. 1.3
COMPUTER HARDWARE REVIEW
25
L2
L2
L2
L2
L2 cache
L1!
cache
(a)
(b)
Core 1
Core 2
Core 3
Core 4
Core 1
Core 2
Core 3
Core 4
Figure 1-8. (a) A quad-core chip with a shared L2 cache. (b) A quad-core chip
with separate L2 caches.
satisfies all of these goals, so a different approach is taken. The memory system is
constructed as a hierarchy of layers, as shown in Fig. 1-9, which would be typical
for a desktop computer or a server (notebooks use SSDs). The top layers have
higher speed, smaller capacity, and greater cost per bit than the lower ones, often
by factors of a billion or more.
Registers
Cache
Main memory
 
Typical capacity
Typical access time
<1 nsec
1-8 nsec
 10-50 nsec
10 msec / 10s -100s usec
<1 KB
4-8 MB
 16-64 GB
 2-16+ TB
optional
persistent
memory 
{
Magnetic disk / SSD
Figure 1-9. A typical memory hierarchy. The numbers are very rough approximations.
The top layer consists of the registers internal to the CPU. They are made of
the same material as the CPU and are thus just as fast as the CPU. Consequently,
there is no delay in accessing them. The storage capacity available in them is on
the order of 32 × 32 bits on a 32-bit CPU and 64 × 64 bits on a 64-bit CPU. Less
than 1 KB in both cases. Programs must manage the registers (i.e., decide what to
keep in them) themselves, in software.
Next comes the cache memory, which is mostly controlled by the hardware.
Main memory is divided up into cache lines, typically 64 bytes, with addresses 0
to 63 in cache line 0, 64 to 127 in cache line 1, and so on. The most heavily used
cache lines are kept in a high-speed cache located inside or very close to the CPU.
When the program needs to read a memory word, the cache hardware checks to see
if the line needed is in the cache. If it is, called a cache hit, the request is satisfied
from the cache and no memory request is sent over the bus to the main memory.
