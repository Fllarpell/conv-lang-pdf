110
PROCESSES AND THREADS
CHAP. 2
thread from affecting the others. With blocking system calls, it is hard to see how
this goal can be achieved readily.
The system calls could all be changed to be nonblocking (e.g., a read on the
keyboard would just return 0 bytes if no characters were already buffered), but
requiring changes to the operating system is unattractive. Besides, one argument
for user-level threads was precisely that they could run with existing operating 
systems. In addition, changing the semantics of read will require changes to many
user programs.
Another alternative is available in the event that it is possible to tell in advance
if a call will block. In most versions of UNIX, a system call, select, exists, which
allows the caller to tell whether a prospective read will block. When this call is
present, the library procedure read can be replaced with a new one that first does a
select call and then does the read call only if it is safe (i.e., will not block). If the
read call will block, the call is not made. Instead, another thread is run. The next
time the run-time system gets control, it can check again to see if the read is now
safe. This approach requires rewriting parts of the system call library, and is 
inefficient and inelegant, but there is little choice. The code placed around the system
call to do the checking is called a wrapper. (As we shall see, many operating 
systems have even more efficient mechanisms for asynchronous I/O, such as epoll on
Linux and kqueue on FreeBSD).
Somewhat analogous to the problem of blocking system calls is the problem of
page faults. We will study these in Chap. 3. For the moment, suffice it to say that
computers can be set up in such a way that not all of the program is in main 
memory at once. If the program calls or jumps to an instruction that is not in memory, a
page fault occurs and the operating system will go and get the missing instruction
(and its neighbors) from disk. This is called a page fault. The process is blocked
while the necessary instruction is being located and read in. If a thread causes a
page fault, the kernel, unaware of even the existence of threads, naturally blocks
the entire process until the disk I/O is complete, even though other threads might
be runnable.
Another problem with user-level thread packages is that if a thread starts 
running, no other thread in that process will ever run unless the first thread voluntarily
gives up the CPU. Within a single process, there are no clock interrupts, making it
impossible to schedule processes in round-robin fashion (taking turns). Unless a
thread exits the run-time system of its own free will, the scheduler will never run.
One possible solution to the problem of threads running forever is to hav e the
run-time system request a clock signal (interrupt) once a second to give it control,
but this, too, is crude and messy to program. Periodic clock interrupts at a higher
frequency are not always possible, and even if they are, the total overhead may be
substantial. Furthermore, a thread might also need a clock interrupt, interfering
with the run-time systemâ€™s use of the clock.
Another, and really the most devastating, argument against user-level threads is
that programmers typically want threads precisely in applications where threads
